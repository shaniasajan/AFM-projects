> hello,world! 

Welcome to **my world** of AFM projects related to data. 

Through my specialization in Data Analytics offered by the School of Accounting & Finance, I have been able to explore different business cases to understand how powerful data is, and how it can help identify & solve a variety of business problems in our ever-evolving world today. It has also helped me to understand the accounting & finance world on a deeper level, knowing that there is a world of numbers outside financial statements that are also used to make key financial decisions. It is crucial for organizations with access to large masses of data to leverage this asset in order to meet the needs of different stakeholders, and recognize the potential for growth in the future. 

AFM 112 [Analytic Methods for Business 1] was the first class I took that introduced me to R, which I was happy to find was within the same family as other programming languages such as Python. Here, I learned introductory codes, and the importance of different packages such as:

library(tidyverse)

I learned how to code data with a statistical approach, understanding the basics about a particular dataset such as the median and finding the outliers that made an impact on the dataset as a whole. I was intruiged by how much information can be filtered based on what you needed to find, and further learned the value of getting what you need from data, using codes such as:

dt1 %>% 
  select(Store, SalesQuantity, Revenue, productCost, grossProfit) %>% 
  group_by(Store) %>% 
  summarize(storeSales =sum(SalesQuantity), 
            storeRevenue = sum(Revenue), 
            storeCOGS = sum(productCost), 
            storeGP = sum(grossProfit), 
            storeGPM = storeGP/storeRevenue)*100

In my second year, AFM 244 [Analytic Methods for Business 3] was where I first learned about dummy variables, and the use of forecasts to identify how a business could change in the future, given certain facts. This was also the course that introduced ARIMA models, where I would use codes such as:

evaluated_arima_1 %>% ggplot(aes(x=date, y=qSales)) + 
  geom_line() +
  geom_line(aes(y=`Point Forecast`), color='blue', linetype='dashed') +
  geom_line(aes(y=`Lo 80`), color='red', linetype='dashed') +
  geom_line(aes(y=`Hi 80`), color='red', linetype='dashed')
evaluated_arima_1

There was so much information you could derive with different models, and it was helpful to see visual representations of information through graphs, and tables that summarized information so that it was easily diggestable. 

It was in AFM 346 [Applications of Predictive Analytics in Accounting and Finance] that I was able to see the bigger picture of machine learning, and the use of Rmd files, convertible to HTML files, so that text, coding, and its outputs were able to be seen effectively on one page. We were encouraged to really understand what each code meant for our analysis, and what problem we were trying to solve by the end of each task. We were introduced to feature engineering, and more advanced models such as KNN & linear regression to match certain problems with datasets. The coding for these projects often came with assessing the final models that were created, and looked like the following: 

final_fit <- 
  wf_lm3 %>% 
  finalize_workflow(parameters = best_lm_model) %>% 
  fit(train_data)

predictions_test <-
  predict(final_fit, test_data) 

test_metrics <- predictions_test %>%
  bind_cols(test_data) %>%
  metrics(truth = Usage, estimate = .pred)

test_metrics


